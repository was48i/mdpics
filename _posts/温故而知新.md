---
title: 温故而知新
date: 2018-11-11 01:32:57
tags:
  - DevPrepares
---
## 从 Hello World 说起
很多问题看似很简单，但实际上我们并没有一个非常清晰的思路；或者在我们脑海里有着模糊的印象，但真正到某些细节的时候可能又模糊不清了。
从基本的编译、静态链接到操作系统如何装载程序、动态链接及运行库和标准库的实现，甚至一些操作系统的机制，力争深入浅出地将这些问题层层剥开，最终使得这些程序运行背后的机制形成一个**非常清晰而流畅的脉络**。
## 万变不离其宗
将计算机的范围限定在：采用兼容 x86 指令集的 32 位 CPU 的个人计算机。
- 系统程序开发者：多如牛毛的硬件设备中，三个部件最为关键：CPU、内存和 I/O 控制芯片。
- 普通应用程序开发者：关心 CPU，其他的硬件细节基本不用关心。
- 高级平台开发者：连 CPU 都不需要关心，平台（Java、.NET 等）提供了一个通用的抽象的计算机。

<!--more-->
早期的计算机没有很复杂的图形功能，CPU 的核心频率不高，跟内存的频率一样，直接连接在同一个`总线（Bus）`上。为了能够让 CPU 能够和 I/O 设备进行通信，每个设备都会有一个相应的 I/O 控制器。
![](https://raw.githubusercontent.com/was48i/mPOST/master/DevPrepares/1-1.jpeg)
为了协调 CPU、内存和高速的图像设备，专门设计了一个高速的**北桥芯片**（Northbridge），以便它们之间能够高速地交换数据。为了避免设计的复杂，又设计了专门处理低速设备的**南桥芯片**（Southbridge）。系统总线上采用的是 PCI 结构，低速设备上采用的是 ISA 总线。
![](https://raw.githubusercontent.com/was48i/mPOST/master/DevPrepares/1-2.jpeg)
### SMP 与多核
CPU 的频率被 4GHz 的“天花板”所限制，人们开始想办法从另外一个角度来提高 CPU 的速度，就是增加 CPU 的数量。最常见的一种形式就是**对称多处理器**（SMP，Symmertical Multi-Processing），理想情况下，速度的提高与 CPU 的数量成正比。实际上并非如此，因为程序并不能分解成若干个完全不相干的子问题，当然很多时候多处理器是非常有用的，比如：在大型数据库、网络服务器上，同时处理大量的相互独立的请求。
“被打包”的处理器之间共享比较昂贵的缓存部件，只保留多个核心，这就是**多核处理器**（Multi-core Processor）的基本想法。
## 站得高，望得远
> 计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决。

用于管理计算机本身的软件称为`系统软件`。
- 平台性的：操作系统内核、驱动程序、运行库和数以千计的系统工具。
- 用于程序开发的：编译器、汇编器、链接器等开发工具和开发库。

![](https://raw.githubusercontent.com/was48i/mPOST/master/DevPrepares/1-3.jpeg)
每个层次之间都须要相互通信，通信的协议称为`接口（Interface）`，接口的下面那层是接口的提供者，由它定义接口；接口的上面那层是接口的使用者，它使用该接口来实现所需要的功能。
开发工具与应用程序是属于同一层次的，都使用**应用程序编程接口**（Application Programming Interface），运行库使用操作系统提供的**系统调用接口**（System call Interface），系统调用接口实现中往往以**软件中断**（Software Interrupt）的方式提供。硬件的接口被叫做**硬件规格**（Hardware Specification），决定了驱动程序如何操作硬件，如何与硬件进行通信。
## 操作系统做什么
- 提供抽象的接口。
- 管理硬件资源：CPU、存储器（内存和磁盘）和 I/O 设备。

### 不要让 CPU 打盹
当某个程序暂时无须使用 CPU 时，监控程序就把另外的正在等待 CPU 资源的程序启动，使得 CPU 能够充分地利用起来。这种被称为**多道程序**（Multiprogramming）的方法看似很原始，但是它当时的确大大提高了 CPU 的利用率。
每个程序运行一段时间以后都主动让出 CPU 给其他程序，使得一段时间内每个程序都有机会运行一小段时间。这种程序协作模式叫做**分时系统**（Time-Sharing System），完整的操作系统雏形已经逐渐形成了。
**多任务系统**（Multi-tasking），操作系统接管了所有的硬件资源，并且本身运行在一个受硬件保护的级别，所有的应用程序都以`进程（Process）`的方式运行在比操作系统权限更低的级别，进程之间的地址空间相互隔离。CPU 的分配方式采用`抢占式（Preemptive）`，在多个进程间快速地切换，造成了很多进程都在同时运行的假象。
### 设备驱动
繁琐的硬件细节全都交给了操作系统，具体地讲是操作系统中的**硬件驱动程序**（Device Driver）来完成，驱动程序往往跟操作系统内核一起运行在特权级。
现代的硬盘普遍使用一种叫做 LBA（Logical Block Address）的方式，当我们给出一个逻辑的扇区号时，硬盘的电子设备会将其转换成实际的盘面、磁道等位置。
## 内存不够怎么办
进程的总体目标是希望每个进程从逻辑上来看都可以独占计算机的资源，那么很明显的一个问题是：**如何将计算机上有限的物理内存分配给多个程序使用**。
- 地址空间不隔离：很容易改写其他程序的内存数据。
- 内存使用效率低：有大量的数据在换入换出，导致效率十分低下。
- 程序运行的地址不确定：程序每次需要装入运行时，空闲区域的位置是不确定的。

解决这几个问题的思路：增加中间层。我们把程序给出的地址看作是一种**虚拟地址**（Virtual Address），然后通过某些映射的方法，将这个虚拟地址转换成实际的物理地址。
### 关于隔离
地址空间分两种：
- 虚拟地址空间（Virtual Address Space）
- 物理地址空间（Physical Address Space）

每个进程都有自己独立的虚拟空间，只能访问自己的地址空间，这样就有效地做到了进程的隔离。
### 分段（Segmentation）
分段的方法还是没有解决我们的第二个问题，即内存使用效率的问题。这种方法还是显得粗糙，粒度比较大。
### 分页（Paging）
分页的基本方法是把地址空间人为地等分成固定大小的页，由操作系统选择决定页的大小。
在这里，我们把虚拟空间的页就叫**虚拟页**（VP，Virtual Page），把物理内存中的页叫做**物理页**（PP，Physical Page），把磁盘中的页叫做**磁盘页**（DP，Disk Page）。虚拟空间的页被映射到同一个物理页，这样就可以实现内存共享。
虚拟存储的实现需要依靠硬件的支持，采用一个叫 **MMU**（Memory Management Unit）的部件来进行页映射。一般 MMU 都集成在 CPU 内部，不会以独立的部件存在。
![](https://raw.githubusercontent.com/was48i/mPOST/master/DevPrepares/1-4.jpeg)
## 众人拾柴火焰高
### 线程基础
线程的概念、线程的调度、线程安全、用户线程与内核线程之间的映射关系。
#### 什么是线程
`线程（Thread）`有时候被称为**轻量级进程**（Lightweight Process，LWP），是程序执行流的最小单元。
一个标准的线程由线程 ID、当前指令指针（PC）、寄存器集合和堆栈组成。对于多进程应用，多线程在数据共享方面效率要高很多。
![](https://raw.githubusercontent.com/was48i/mPOST/master/DevPrepares/1-5.jpeg)
#### 线程的访问权限
线程也拥有自己的私有存储空间。
![](https://raw.githubusercontent.com/was48i/mPOST/master/DevPrepares/1-6.jpeg)
#### 线程调度与优先级
当线程数量 <= 处理器数量时，线程的并发是真正的并发。在单处理器对应多线程的情况下，并发是一种模拟出来的状态。
如果在时间片用尽之前进程就开始等待某事件，那么它将进入等待状态。
![](https://raw.githubusercontent.com/was48i/mPOST/master/DevPrepares/1-7.jpeg)
现在主流的调度方式不尽相同，但都带有**优先级调度**（Priority Schedule）和**轮转法**（Round Robin）的痕迹。
IO 密集型线程（IO Bound Thread）总是比 CPU 密集型线程容易得到优先级的提升。
为了避免**饿死**（Starvation）现象，调度系统常常会逐步提升那些等待了过长时间的得不到执行的线程的优先级。
线程的优先级改变一般有三种方式：
- 用户指定优先级。
- 根据进入等待状态的频繁程度提升或降低优先级。
- 长时间得不到执行而被提升优先级。

#### 可抢占线程和不可抢占线程
不可**抢占**（Preemption）线程的线程调度的时机是确定的，只会发生在线程主动放弃执行或线程等待某事件的时候。
#### Linux 的多线程
Linux 将所有的执行实体（进程、线程）都称为**任务**（Task）。实际意义上，共享了同一个内存空间的多个任务构成了一个进程，这些任务也就成了这个进程里的线程。
![](https://raw.githubusercontent.com/was48i/mPOST/master/DevPrepares/1-8.jpeg)
fork 和 exec 通常用于产生新任务，而如果要产生新线程，则可以使用 clone。
### 线程安全
多线程程序在并发时，数据的一致性变得非常重要。
#### 竞争与原子操作
把单指令的操作称为**原子的**（Atomic），单条指令的执行是不会被打断的。要保证一个复杂的数据结构更改的原子性，原子操作指令就力不从心了，需要更加通用的手段：`锁（Lock）`。
#### 同步与锁
所谓**同步**（Synchronization），即指在一个线程访问数据未结束的时候，其他线程不得对同一个数据进行访问。
同步的最常见方法是使用锁，每一个线程在访问数据或资源之前首先试图**获取**（Acquire）锁，并在访问结束之后**释放**（Release）锁。
**二元信号量**（Binary Semaphore）是最简单的一种锁，它只有两种状态：占用与非占用。
多元信号量简称**信号量**（Semaphore），一个初始值为 N 的信号量允许 N 个线程并发访问。
信号量在整个系统可以被任意线程获取并释放，而**互斥量**（Mutex）则要求哪个线程获取了互斥量，哪个线程就要负责释放这个锁。
**临界区**（Critical Section）是比互斥量更加严格的同步手段。互斥量和信号量在系统的任何进程里都是可见的，而临界区的作用范围仅限于本进程，其他的进程无法获取该锁。
**读写锁**（Read-Write Lock）致力于一种更加特定的场合的同步，信号量、互斥量或临界区对于读取频繁，而仅仅偶尔写入的情况，会显得非常低效。读写锁有两种获取方式：共享的（Shared）或独占的（Exclusive）。
![](https://raw.githubusercontent.com/was48i/mPOST/master/DevPrepares/1-9.jpeg)
**条件变量**（Condition Variable）可以让许多线程一起等待某个事件的发生，当事件发生时（条件变量被唤醒），所有的线程可以一起恢复执行。
线程可以有两种操作：
- 等待条件变量
- 唤醒条件变量

#### 可重入（Reentrant）与线程安全
> 可重入是并发安全的强力保障，一个可重入的函数可以在多线程环境下放心使用。

一个函数被重入，表示这个函数没有执行完成，由于外部因素或内部调用，又一次进入该函数执行。分为两种情况：
- 多个线程同时执行这个函数。
- 函数自身（可能是经过多层调用之后）调用自身。

#### 过度优化
即使合理地使用了锁，也不一定能保证线程安全，源于落后的编译器技术已经无法满足日益增长的并发需求。很多看似无错的代码在优化和并发面前又产生了麻烦。
`volatile 关键字`试图阻止过度优化，可以做到两件事：
- 阻止编译器为了提高速度将一个变量缓存到寄存器内而不写回。
- 阻止编译器调整操作 volatile 变量的指令顺序。

即使 volatile 能够阻止编译器调整顺序，也无法阻止 CPU 动态调度换序。
要保证线程安全，阻止 CPU 换序是必需的，通常调用 CPU 提供的 `barrier 指令`。一条 barrier 指令会阻止 CPU 将该指令之前的指令交换到 barrier 之后，反之亦然。
### 三种线程模型
线程的并发执行是由多处理器或操作系统调度来实现的，但实际情况要更为复杂一些，内核线程和我们之前讨论的一样。然而，用户实际使用的是存在于用户态的用户线程，用户态线程并不一定在操作系统内核里对应同等数量的内核线程。
#### 一对一模型
一个用户使用的线程就唯一对应一个内核使用的线程（反之不一定）。
![](https://raw.githubusercontent.com/was48i/mPOST/master/DevPrepares/1-10.jpeg)
线程之间的并发是真正的并发，一对一线程缺点有两个：
- 由于许多操作系统限制了内核线程的数量，因此一对一线程会让用户的线程数量受到限制。
- 许多操作系统内核线程调度时，上下文切换的开销较大，导致用户线程的执行效率下降。

#### 多对一模型
多对一模型的好处是高效的上下文切换和几乎无限制的线程数量。
![](https://raw.githubusercontent.com/was48i/mPOST/master/DevPrepares/1-11.jpeg)
多对一模型一大问题是，如果其中一个用户线程阻塞，那么所有的线程都将无法执行，因为此时内核里的线程也随之阻塞了。
另外，在多处理器系统上，处理器的增多对多对一模型的线程性能也不会有明显的帮助。
#### 多对多模型
多对多模型结合了多对一模型和一对一模型的特点。
![](https://raw.githubusercontent.com/was48i/mPOST/master/DevPrepares/1-12.jpeg)
